from langchain_core.messages import AIMessage
from configuration import state
from prompts import graph_and_exploitation_inference_prompt
from .node_utils import OPEN_AI_KEY
from openai import BadRequestError 
import logging
from pydantic import BaseModel, ValidationError, Field
import instructor
from openai import OpenAI

from typing import Dict, List, Any, Tuple
import copy
import ipaddress

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PhaseDelta(BaseModel):
    phase: str
    evidence_quotes: List[str]

class EdgeUpdate(BaseModel):
    from_: str = Field(..., alias="from")
    to: str
    new_phases: List[PhaseDelta]

class ContainersExploitationUpdate(BaseModel):
    ip: str
    service: str
    level_prev: int
    level_new: int
    evidence_quotes: List[str]

class DeltaOutput(BaseModel):
    reasoning: str
    edge_updates: List[EdgeUpdate] = []
    containers_exploitation_updates: List[ContainersExploitationUpdate] = []


PHASE_RANK = {
  "scan":0,
  "initial-access/rce":1,
  "data-exfil-user":2,
  "privilege-escalation":3,
  "data-exfil-root":4
}

EXPLOITATION_FROM_PHASE = {
  "scan": 25,
  "initial-access/rce": 50,
  "data-exfil-user": 75,
  "privilege-escalation": 100,
  "data-exfil-root": 100
}

def ip_in_subnet(ip: str, subnet: str) -> bool:
    try:
        return ipaddress.ip_address(ip) in ipaddress.ip_network(subnet)
    except Exception:
        return False

def find_edge(edges: List[Dict[str,Any]], attacker: str, container: str) -> Tuple[int, Dict[str,Any] | None]:
    for i, e in enumerate(edges):
        if e.get("from") == attacker and e.get("to") == container:
            return i, e
    return -1, None

def validate_phase_name(phase: str) -> bool:
    return phase in PHASE_RANK

def merge_deltas_into_graph(prev_graph: Dict[str,Any],
                            prev_exploitation: List[Dict[str,Any]],
                            vulnerable_containers: List[Dict[str,Any]],
                            deltas: DeltaOutput,
                            ) -> Dict[str,Any]:
    # deep copy to avoid mutating inputs on failure
    graph = copy.deepcopy(prev_graph)
    edges = graph.get("edges", [])
    interesting = { (n["ip"], n["service"]) for n in graph.get("interesting", []) }
    reasoning_lines = []

    # Build quick lookup for container config and exploitation
    containers_services = { vc["ip"]: vc["service"] for vc in vulnerable_containers }
    exploit_map = { pe["ip"]: copy.deepcopy(pe) for pe in prev_exploitation }  # keyed by ip

    # If no deltas -> return prev unchanged
    if not deltas.edge_updates and not deltas.containers_exploitation_updates:
        rolled = []
    # Build quick lookup for container config (you already have vulnerable_containers)
        containers_services = { vc["ip"]: vc["service"] for vc in vulnerable_containers }
        for pe in prev_exploitation:
            ip = pe["ip"]
            service = pe.get("service", containers_services.get(ip))
            # roll level_prev forward to last level_new
            level_prev = pe.get("level_new", pe.get("level_prev", 0))
            rolled.append({
                "ip": ip,
                "service": service,
                "level_prev": level_prev,
                "level_new": level_prev,
                "changed": False,
                "evidence_quotes": []
            })

        return {
            "reasoning": "no updates in delta; returning previous graph unchanged",
            "inferred_attack_graph": prev_graph,
            "containers_exploitation": rolled
        }

    # 1) Apply edge updates
    for eu in deltas.edge_updates:
        att = eu.from_
        vc = eu.to
        # SERVICE & IP GUARDS
        if not ip_in_subnet(att, "192.168.100.0/24"):
            raise ValueError(f"attacker {att} outside attacker subnet")
        if not ip_in_subnet(vc, "172.20.0.0/24"):
            raise ValueError(f"container {vc} outside containers subnet")
        if vc not in containers_services:
            raise ValueError(f"container {vc} not in vulnerable_containers")

        idx, existing_edge = find_edge(edges, att, vc)
        created_new_edge = False
        if existing_edge is None:
            # create new edge skeleton
            created_new_edge = True
            existing_edge = {
                "from": att,
                "to": vc,
                "phases": [],
                "current_phase": None,
                "vector": None
            }
            edges.append(existing_edge)
            idx = len(edges) - 1
        
        added_phases = []
        for pd in eu.new_phases:
            if not validate_phase_name(pd.phase):
                raise ValueError(f"unknown phase {pd.phase}")
            # Check evidence quotes exist
            if not pd.evidence_quotes or any(not q or not isinstance(q, str) for q in pd.evidence_quotes):
                raise ValueError("each added phase must include >=1 exact evidence_quotes")
            # If phase already present on edge, skip
            already = False
            for existing_phase in existing_edge["phases"]:
                if existing_phase["phase"] == pd.phase:
                    already = True
                    break
            if already:
                continue
            # Add phase object
            phase_obj = {
                "phase": pd.phase,
                "evidence_quotes": pd.evidence_quotes,
            }
            existing_edge["phases"].append(phase_obj)
            added_phases.append(pd.phase)

        if added_phases:
            # Sort/normalize phases by rank for predictable output
            existing_edge["phases"].sort(key=lambda p: PHASE_RANK.get(p["phase"], 0))
            # update current_phase / vector to the highest rank
            highest = max(existing_edge["phases"], key=lambda p: PHASE_RANK[p["phase"]])
            existing_edge["current_phase"] = highest["phase"]
            existing_edge["vector"] = highest["phase"]
            
    # 2) Recompute exploitation per container deterministically as MAX over edges
    # Build per-container edge list
    per_vc_edges = {}
    for e in edges:
        per_vc_edges.setdefault(e["to"], []).append(e)

    containers_updates_result = []
    for vc_ip, service in containers_services.items():
        prev_entry = exploit_map.get(vc_ip, {"ip": vc_ip, "service": service, "level_prev": 0, "level_new": 0, "changed": False, "evidence_quotes": []})
        level_prev = prev_entry.get("level_new", prev_entry.get("level_prev", 0))

        # compute max over edges
        max_level = level_prev
        evidence_for_level = []
        for e in per_vc_edges.get(vc_ip, []):
            # highest phase of edge -> its exploitation mapping
            if not e.get("phases"):
                continue
            highest_phase = max(e["phases"], key=lambda p: PHASE_RANK[p["phase"]])
            lvl = EXPLOITATION_FROM_PHASE.get(highest_phase["phase"], 0)
            if lvl > max_level:
                max_level = lvl
                # minimal evidence: take the quote from the newly added phase(s) if present; fallback to highest_phase quote
                evidence_for_level = highest_phase.get("evidence_quotes", [])[:1]
        # enforce monotonicity
        if max_level < level_prev:
            max_level = level_prev

        changed = (max_level != level_prev)
        if changed:
            # If level_new >=66 -> ensure container in interesting set
            if max_level >= 66:
                interesting.add((vc_ip, service))
            containers_updates_result.append({
                "ip": vc_ip,
                "service": service,
                "level_prev": level_prev,
                "level_new": max_level,
                "evidence_quotes": evidence_for_level
            })

    # Build full, rolled-forward state for all containers
    full_state = []
    for vc_ip, service in containers_services.items():
        # start from previous baseline (take prev level from the previous epoch, if present)
        prev_entry = exploit_map.get(vc_ip, {
            "ip": vc_ip, "service": service,
            "level_prev": 0, "level_new": 0,
            "changed": False, "evidence_quotes": []
        })

        # previous level must reflect the previous epoch's final level (if available)
        level_prev = prev_entry.get("level_new", prev_entry.get("level_prev", 0))

        # determine proposed new level as max over edges (do not reduce below previous)
        level_new = level_prev
        for e in per_vc_edges.get(vc_ip, []):
            if e.get("phases"):
                highest_phase = max(e["phases"], key=lambda p: PHASE_RANK[p["phase"]])
                lvl = EXPLOITATION_FROM_PHASE.get(highest_phase["phase"], 0)
                if lvl > level_new:
                    level_new = lvl

        # enforce monotonicity (should already hold, but be explicit)
        if level_new <= level_prev:
            level_new = level_prev

        changed = (level_new != level_prev)

        # try to attach evidence if we recorded an update for this container earlier
        evidence = []
        for upd in containers_updates_result:
            if upd["ip"] == vc_ip:
                evidence = upd.get("evidence_quotes", [])
                break

        full_state.append({
            "ip": vc_ip,
            "service": service,
            "level_prev": level_prev,
            "level_new": level_new,
            "changed": changed,
            "evidence_quotes": evidence
        })


    # Update graph object fields and interesting list
    graph["edges"] = edges
    graph["interesting"] = [{"ip": ip, "service": svc} for ip, svc in sorted(list(interesting))]
    # final output
    return {
        "reasoning": "; ".join(reasoning_lines),
        "inferred_attack_graph": graph,
        "containers_exploitation": full_state
    }

def get_last_epoch_fields(last_epoch):
    last_exploitation = []
    last_attack_graph = {}
    if last_epoch:
        last_epoch = last_epoch[0].value
        last_exploitation = last_epoch.get('containers_exploitation', [])
        last_attack_graph = last_epoch.get('inferred_attack_graph', {})

    return last_exploitation, last_attack_graph

async def graph_and_exploitation_inference(state: state.AgentState, config):
    """
    Infers/Update the attack graph from security events
    """
    logger.info("Inference Agent")
    episodic_memory = config.get("configurable", {}).get("store")
    model_config = config.get("configurable", {}).get("model_config", "large:4.1")
    epoch_num = config.get("configurable", {}).get("epoch_num")


    last_epoch = episodic_memory.get_recent_iterations(limit=1)
    last_exploitation, last_attack_graph = get_last_epoch_fields(last_epoch)
    
    if not last_attack_graph or "edges" not in last_attack_graph:
        logger.info("Initializing first-epoch attack graph baseline")
        last_attack_graph = {"edges": [], "interesting": []}

    if not isinstance(last_exploitation, list) or len(last_exploitation) == 0:
        logger.info("Initializing first-epoch containers exploitation baseline")
        last_exploitation = [
            {
                "ip": h["ip"],
                "service": h["service"],
                "level_prev": 0,
                "level_new": 0,
                "changed": False,
                "evidence_quotes": []
            }
            for h in state.vulnerable_containers
        ]

    message = ""
    size, version = model_config.split(':')
    model_name = f"gpt-{version}"
    logger.info(f"Using: {model_name}")

    current_graph = copy.deepcopy(last_attack_graph)
    current_exploitation = copy.deepcopy(last_exploitation)

    message_lines = []


    try:
        if version == "4.1":
            agent = instructor.from_openai(OpenAI(api_key=OPEN_AI_KEY))
            logger.info(f"Vulnerable Containers: {state.vulnerable_containers}")
            for container in state.vulnerable_containers:
                container_ip = container.get("ip")
                container_service = container.get("service")
                logger.info(f"Processing container {container_ip} / {container_service}")

                events_for_container = []
                for ev in state.security_events:
                    ev_ip = ev.get("ip")
                    ev_service = ev.get("service")
                    if (ev_ip is not None and ev_ip == container_ip) or (ev_service is not None and ev_service == container_service):
                        events_for_container.append(ev)

                if not events_for_container:
                    logger.info(f"No security events for container {container_ip}; skipping LLM call")
                    continue
                
                messages = [
                    {"role" : "system", "content" : graph_and_exploitation_inference_prompt.SYSTEM_PROMPT},
                    {"role" : "system", "content": graph_and_exploitation_inference_prompt.USER_PROMPT.substitute(
                        security_events=events_for_container,
                        vulnerable_containers=container,
                        previous_exploitation=current_exploitation,
                        previous_attack_graph=current_graph
                    )}
                ]

                logger.info(f"Calling LLM for container {container_ip}")
                try:

                    response: DeltaOutput = agent.chat.completions.create(
                        model=model_name,
                        response_model=DeltaOutput,
                        temperature=0.2,
                        messages=messages # type: ignore
                    )

                    merged = merge_deltas_into_graph(
                        prev_graph=current_graph,
                        prev_exploitation=current_exploitation,
                        vulnerable_containers=state.vulnerable_containers,
                        deltas=response
                    )
                    logger.info(f"Merged: {merged}")

                    current_graph = merged["inferred_attack_graph"]
                    current_exploitation = merged["inferred_attack_graph"]
                    message_lines.append(f"[{container_ip}] LLM reasoning: {merged.get("reasoning", "n/a")}")
                except BadRequestError as e:
                    logger.error(f"Error: {e}")
                except Exception as e:
                    logger.error(f"Error parsing json in attack graph inference:\n{e}")

        final_text = []
        final_text.extend(message_lines)
        final_text.append(f"Inferred Attack Graph: {str(current_graph)}")
        final_text.append(f"Containers' Exploitaiton: {str(current_exploitation)}")
        message = AIMessage(content="\n".join(final_text))


        return {
            "messages": [message],
            "inferred_attack_graph": current_graph, 
            "containers_exploitation": current_exploitation
        }
    except Exception as e:
        logger.error(f"Error in per-container attack graph inference: {e}")
        return {
            "messages" : [AIMessage(content="; ".join(message_lines) or "error during inference")]
        }